{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "006acbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MyPC\\AppData\\Local\\Temp\\ipykernel_29852\\2508284979.py:2: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(r\"telecom_market_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"telecom_market_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4da2f567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                   int64\n",
       "month                 object\n",
       "circle                object\n",
       "type_of_connection    object\n",
       "service_provider      object\n",
       "value                 object\n",
       "unit                  object\n",
       "notes                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5d2ef59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>circle</th>\n",
       "      <th>type_of_connection</th>\n",
       "      <th>service_provider</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025</td>\n",
       "      <td>April</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>wireless</td>\n",
       "      <td>Bharti Airtel (Including Tata Tele.)</td>\n",
       "      <td>33965795</td>\n",
       "      <td>value in absolute number</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025</td>\n",
       "      <td>April</td>\n",
       "      <td>Assam</td>\n",
       "      <td>wireless</td>\n",
       "      <td>Bharti Airtel (Including Tata Tele.)</td>\n",
       "      <td>12314102</td>\n",
       "      <td>value in absolute number</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025</td>\n",
       "      <td>April</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>wireless</td>\n",
       "      <td>Bharti Airtel (Including Tata Tele.)</td>\n",
       "      <td>40967773</td>\n",
       "      <td>value in absolute number</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025</td>\n",
       "      <td>April</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>wireless</td>\n",
       "      <td>Bharti Airtel (Including Tata Tele.)</td>\n",
       "      <td>18877637</td>\n",
       "      <td>value in absolute number</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025</td>\n",
       "      <td>April</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>wireless</td>\n",
       "      <td>Bharti Airtel (Including Tata Tele.)</td>\n",
       "      <td>12401101</td>\n",
       "      <td>value in absolute number</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month          circle type_of_connection  \\\n",
       "0  2025  April  Andhra Pradesh           wireless   \n",
       "1  2025  April           Assam           wireless   \n",
       "2  2025  April           Bihar           wireless   \n",
       "3  2025  April           Delhi           wireless   \n",
       "4  2025  April         Gujarat           wireless   \n",
       "\n",
       "                       service_provider     value                      unit  \\\n",
       "0  Bharti Airtel (Including Tata Tele.)  33965795  value in absolute number   \n",
       "1  Bharti Airtel (Including Tata Tele.)  12314102  value in absolute number   \n",
       "2  Bharti Airtel (Including Tata Tele.)  40967773  value in absolute number   \n",
       "3  Bharti Airtel (Including Tata Tele.)  18877637  value in absolute number   \n",
       "4  Bharti Airtel (Including Tata Tele.)  12401101  value in absolute number   \n",
       "\n",
       "  notes  \n",
       "0   NaN  \n",
       "1   NaN  \n",
       "2   NaN  \n",
       "3   NaN  \n",
       "4   NaN  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f55b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April <class 'str'>\n",
      "March <class 'str'>\n",
      "February <class 'str'>\n",
      "January <class 'str'>\n",
      "December <class 'str'>\n",
      "November <class 'str'>\n",
      "October <class 'str'>\n",
      "September <class 'str'>\n",
      "August <class 'str'>\n",
      "July <class 'str'>\n",
      "June <class 'str'>\n",
      "May <class 'str'>\n",
      "Number of unique months: 12\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for i in df['month'].unique():\n",
    "    print(i,type(i))\n",
    "    c+=1\n",
    "print('Number of unique months before cleaning:',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21781915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andhra Pradesh <class 'str'>\n",
      "Assam <class 'str'>\n",
      "Bihar <class 'str'>\n",
      "Delhi <class 'str'>\n",
      "Gujarat <class 'str'>\n",
      "Haryana <class 'str'>\n",
      "Himachal Pradesh <class 'str'>\n",
      "Jammu and Kashmir <class 'str'>\n",
      "Karnataka <class 'str'>\n",
      "Kerala <class 'str'>\n",
      "Kolkata <class 'str'>\n",
      "Madhya Pradesh <class 'str'>\n",
      "Maharashtra <class 'str'>\n",
      "Mumbai <class 'str'>\n",
      "North East <class 'str'>\n",
      "Odisha <class 'str'>\n",
      "Punjab <class 'str'>\n",
      "Rajasthan <class 'str'>\n",
      "Tamil Nadu <class 'str'>\n",
      "Uttar Pradesh (East) <class 'str'>\n",
      "Uttar Pradesh (West) <class 'str'>\n",
      "West Bengal <class 'str'>\n",
      "All India <class 'str'>\n",
      "All india <class 'str'>\n",
      "Tamil Nadu (including Chennai) <class 'str'>\n",
      "Chennai <class 'str'>\n",
      "Andaman and Nicobar Islands <class 'str'>\n",
      "Arunachal Pradesh <class 'str'>\n",
      "Chhattisgarh <class 'str'>\n",
      "Jharkhand <class 'str'>\n",
      "Uttarakhand <class 'str'>\n",
      "North East 1 <class 'str'>\n",
      "North East 2 <class 'str'>\n",
      "North East2 <class 'str'>\n",
      "North East1 <class 'str'>\n",
      "Chattisgarh <class 'str'>\n",
      "Andaman and Nicobar <class 'str'>\n",
      "Uttaranchal <class 'str'>\n",
      "Number of unique circles: 50\n"
     ]
    }
   ],
   "source": [
    "for i in df['circle'].unique():\n",
    "    print(i,type(i))\n",
    "    c+=1\n",
    "print('Number of unique circles before cleaning:',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "43f2b369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bharti Airtel (Including Tata Tele.) <class 'str'>\n",
      "Reliance Communications <class 'str'>\n",
      "Vodafone Idea <class 'str'>\n",
      "BSNL <class 'str'>\n",
      "MTNL <class 'str'>\n",
      "Reliance Jio <class 'str'>\n",
      "BSNL (VNOs) <class 'str'>\n",
      "Bharti Airtel <class 'str'>\n",
      "Tata Teleservices <class 'str'>\n",
      "Vodafone <class 'str'>\n",
      "Idea <class 'str'>\n",
      "Telenor <class 'str'>\n",
      "Aircel <class 'str'>\n",
      "Sistema <class 'str'>\n",
      "Quadrant <class 'str'>\n",
      "Videocon <class 'str'>\n",
      "Telewings <class 'str'>\n",
      "Loop <class 'str'>\n",
      "Unitech <class 'str'>\n",
      "Aircel/Dishnet <class 'str'>\n",
      "Quadrant (HFCL) <class 'str'>\n",
      "S-Tel <class 'str'>\n",
      "Etisalat <class 'str'>\n",
      "Uninor <class 'str'>\n",
      "HFCL <class 'str'>\n",
      "Etisalat/Allianz <class 'str'>\n",
      "Idea/Spice <class 'str'>\n",
      "Vodafone Essar <class 'str'>\n",
      "Loop Telecom Pvt. Ltd. <class 'str'>\n",
      "HFCL Infotel <class 'str'>\n",
      "Sistema Shyam Teleservices Ltd <class 'str'>\n",
      "Spice <class 'str'>\n",
      "BPL Mobile <class 'str'>\n",
      "Tata Telecommunication <class 'str'>\n",
      "STPL <class 'str'>\n",
      "APSFL <class 'str'>\n",
      "V-CON Mobile & Infra Pvt. Ltd. <class 'str'>\n",
      "Bharti Airtel (including Tata Telecommunications) <class 'str'>\n",
      "Reliance <class 'str'>\n",
      "Tata <class 'str'>\n",
      "Teleservice Ltd. <class 'str'>\n",
      "Systema Shyam Teleservices Ltd. <class 'str'>\n",
      "Number of unique service providers before cleaning: 42\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for i in df['service_provider'].unique():\n",
    "    print(i,type(i))\n",
    "    c+=1\n",
    "print('Number of unique service providers before cleaning:',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7339a18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 <class 'numpy.int64'>\n",
      "2024 <class 'numpy.int64'>\n",
      "2023 <class 'numpy.int64'>\n",
      "2022 <class 'numpy.int64'>\n",
      "2021 <class 'numpy.int64'>\n",
      "2020 <class 'numpy.int64'>\n",
      "2019 <class 'numpy.int64'>\n",
      "2018 <class 'numpy.int64'>\n",
      "2017 <class 'numpy.int64'>\n",
      "2016 <class 'numpy.int64'>\n",
      "2015 <class 'numpy.int64'>\n",
      "2014 <class 'numpy.int64'>\n",
      "2013 <class 'numpy.int64'>\n",
      "2012 <class 'numpy.int64'>\n",
      "2011 <class 'numpy.int64'>\n",
      "2010 <class 'numpy.int64'>\n",
      "2009 <class 'numpy.int64'>\n",
      "Number of unique years before cleaning: 17\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for i in df['year'].unique():\n",
    "    print(i,type(i))\n",
    "    c+=1\n",
    "print('Number of unique years before cleaning:',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f4f967b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     58396\n",
       "unique    47600\n",
       "top           0\n",
       "freq       5351\n",
       "Name: value, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cdacddf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    70728.000000\n",
       "mean      2016.026298\n",
       "std          4.748129\n",
       "min       2009.000000\n",
       "25%       2012.000000\n",
       "50%       2016.000000\n",
       "75%       2020.000000\n",
       "max       2025.000000\n",
       "Name: year, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d514e4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from telecom_market_data.csv...\n",
      "Initial data loaded. Shape: (70728, 8)\n",
      "\n",
      "Initial data types:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70728 entries, 0 to 70727\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   year                70728 non-null  int64 \n",
      " 1   month               70728 non-null  object\n",
      " 2   circle              70728 non-null  object\n",
      " 3   type_of_connection  70728 non-null  object\n",
      " 4   service_provider    70728 non-null  object\n",
      " 5   value               58396 non-null  object\n",
      " 6   unit                70728 non-null  object\n",
      " 7   notes               511 non-null    object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 4.3+ MB\n",
      "None\n",
      "\n",
      "Step 2: Checking for missing values...\n",
      "Missing values per column:\n",
      "value    12332\n",
      "notes    70217\n",
      "dtype: int64\n",
      "\n",
      "Step 3: Dropping uninformative columns...\n",
      "Column 'unit' has low variance and will be dropped.\n",
      "\n",
      "Step 4: Removing duplicate rows...\n",
      "Removed 0 duplicate rows.\n",
      "\n",
      "Step 5: Cleaning and standardizing text data...\n",
      "Trimmed whitespace from text columns.\n",
      "\n",
      "Step 6: Optimizing data types...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MyPC\\AppData\\Local\\Temp\\ipykernel_29852\\1583967815.py:14: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_filepath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final cleaned data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70728 entries, 0 to 70727\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype   \n",
      "---  ------              --------------  -----   \n",
      " 0   year                70728 non-null  int64   \n",
      " 1   month               70728 non-null  object  \n",
      " 2   circle              70728 non-null  category\n",
      " 3   type_of_connection  70728 non-null  category\n",
      " 4   service_provider    70728 non-null  category\n",
      " 5   value               53496 non-null  object  \n",
      " 6   notes               511 non-null    object  \n",
      "dtypes: category(3), int64(1), object(3)\n",
      "memory usage: 2.4+ MB\n",
      "\n",
      "Saving cleaned data to cleaned_telecom_data.csv...\n",
      "Done! Your dataset has been cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_dataset(input_filepath, output_filepath):\n",
    "    \"\"\"\n",
    "    Cleans the telecom market dataset.\n",
    "\n",
    "    Args:\n",
    "        input_filepath (str): The path to the raw CSV file.\n",
    "        output_filepath (str): The path to save the cleaned CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        print(f\"Reading data from {input_filepath}...\")\n",
    "        df = pd.read_csv(input_filepath)\n",
    "        print(\"Initial data loaded. Shape:\", df.shape)\n",
    "        print(\"\\nInitial data types:\")\n",
    "        print(df.info())\n",
    "\n",
    "        # --- Data Cleaning Steps ---\n",
    "\n",
    "        '''        \n",
    "        # 1. Create a proper 'date' column\n",
    "        # Combining 'year' and 'month' into a single datetime object for easier analysis.\n",
    "        print(\"\\nStep 1: Creating a 'date' column from 'year' and 'month'...\")\n",
    "        df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'], format='%Y-%B')\n",
    "        df.drop(['year', 'month'], axis=1, inplace=True)\n",
    "        print(\"Dropped 'year' and 'month' columns.\")'''\n",
    "\n",
    "        # 2. Handle missing values\n",
    "        # We will check for any missing values in the dataset.\n",
    "        print(\"\\nStep 2: Checking for missing values...\")\n",
    "        missing_values = df.isnull().sum()\n",
    "        print(\"Missing values per column:\")\n",
    "        print(missing_values[missing_values > 0])\n",
    "        # Based on initial inspection, the 'notes' column might be mostly empty or contain\n",
    "        # non-essential data. If it has many missing values, we can drop it.\n",
    "        # Let's also check columns with low variance.\n",
    "        \n",
    "        # 3. Drop uninformative columns\n",
    "        print(\"\\nStep 3: Dropping uninformative columns...\")\n",
    "        # Check if 'unit' or 'notes' columns have only one unique value\n",
    "        cols_to_drop = []\n",
    "        for col in ['unit', 'notes']:\n",
    "            if col in df.columns and df[col].nunique(dropna=False) <= 1:\n",
    "                cols_to_drop.append(col)\n",
    "                print(f\"Column '{col}' has low variance and will be dropped.\")\n",
    "        \n",
    "        if cols_to_drop:\n",
    "            df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "        # 4. Remove duplicate rows\n",
    "        print(\"\\nStep 4: Removing duplicate rows...\")\n",
    "        initial_rows = len(df)\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        final_rows = len(df)\n",
    "        print(f\"Removed {initial_rows - final_rows} duplicate rows.\")\n",
    "\n",
    "        # 5. Clean text data\n",
    "        # Trimming leading/trailing whitespace from object columns\n",
    "        print(\"\\nStep 5: Cleaning and standardizing text data...\")\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            df[col] = df[col].str.strip()\n",
    "        print(\"Trimmed whitespace from text columns.\")\n",
    "\n",
    "\n",
    "        # 6. Optimize data types\n",
    "        # Convert columns with a limited number of unique values to 'category' type to save memory.\n",
    "        print(\"\\nStep 6: Optimizing data types...\")\n",
    "        for col in ['circle', 'type_of_connection', 'service_provider']:\n",
    "             if col in df.columns:\n",
    "                df[col] = df[col].astype('category')\n",
    "        \n",
    "        print(\"\\nFinal cleaned data info:\")\n",
    "        df.info()\n",
    "\n",
    "        # Reorder columns for better readability\n",
    "        if 'date' in df.columns:\n",
    "            cols = df.columns.tolist()\n",
    "            # Bring date to the front\n",
    "            cols.insert(0, cols.pop(cols.index('date')))\n",
    "            df = df[cols]\n",
    "\n",
    "        # Save the cleaned dataframe to a new CSV file\n",
    "        print(f\"\\nSaving cleaned data to {output_filepath}...\")\n",
    "        df.to_csv(output_filepath, index=False)\n",
    "        print(\"Done! Your dataset has been cleaned successfully.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {input_filepath} was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Define the input and output file paths\n",
    "    # The script expects 'telecom_market_data.csv' to be in the same directory.\n",
    "    INPUT_FILE = 'telecom_market_data.csv'\n",
    "    OUTPUT_FILE = 'cleaned_telecom_data.csv'\n",
    "    \n",
    "    # Run the cleaning function\n",
    "    clean_dataset(INPUT_FILE, OUTPUT_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e49785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"cleaned_telecom_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d6d9ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                   int64\n",
       "month                 object\n",
       "circle                object\n",
       "type_of_connection    object\n",
       "service_provider      object\n",
       "value                 object\n",
       "notes                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8a42a453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>circle</th>\n",
       "      <th>type_of_connection</th>\n",
       "      <th>service_provider</th>\n",
       "      <th>value</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025</td>\n",
       "      <td>April</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>wireless</td>\n",
       "      <td>Bharti Airtel (Including Tata Tele.)</td>\n",
       "      <td>33965795</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025</td>\n",
       "      <td>April</td>\n",
       "      <td>Assam</td>\n",
       "      <td>wireless</td>\n",
       "      <td>Bharti Airtel (Including Tata Tele.)</td>\n",
       "      <td>12314102</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025</td>\n",
       "      <td>April</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>wireless</td>\n",
       "      <td>Bharti Airtel (Including Tata Tele.)</td>\n",
       "      <td>40967773</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025</td>\n",
       "      <td>April</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>wireless</td>\n",
       "      <td>Bharti Airtel (Including Tata Tele.)</td>\n",
       "      <td>18877637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025</td>\n",
       "      <td>April</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>wireless</td>\n",
       "      <td>Bharti Airtel (Including Tata Tele.)</td>\n",
       "      <td>12401101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month          circle type_of_connection  \\\n",
       "0  2025  April  Andhra Pradesh           wireless   \n",
       "1  2025  April           Assam           wireless   \n",
       "2  2025  April           Bihar           wireless   \n",
       "3  2025  April           Delhi           wireless   \n",
       "4  2025  April         Gujarat           wireless   \n",
       "\n",
       "                       service_provider     value notes  \n",
       "0  Bharti Airtel (Including Tata Tele.)  33965795   NaN  \n",
       "1  Bharti Airtel (Including Tata Tele.)  12314102   NaN  \n",
       "2  Bharti Airtel (Including Tata Tele.)  40967773   NaN  \n",
       "3  Bharti Airtel (Including Tata Tele.)  18877637   NaN  \n",
       "4  Bharti Airtel (Including Tata Tele.)  12401101   NaN  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "374eeaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70728 entries, 0 to 70727\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   year                70728 non-null  int64 \n",
      " 1   month               70728 non-null  object\n",
      " 2   circle              70728 non-null  object\n",
      " 3   type_of_connection  70728 non-null  object\n",
      " 4   service_provider    70728 non-null  object\n",
      " 5   value               53496 non-null  object\n",
      " 6   notes               511 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f2c671dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bharti Airtel (Including Tata Tele.)\n",
      "Reliance Communications\n",
      "Vodafone Idea\n",
      "BSNL\n",
      "MTNL\n",
      "Reliance Jio\n",
      "BSNL (VNOs)\n",
      "Bharti Airtel\n",
      "Tata Teleservices\n",
      "Vodafone\n",
      "Idea\n",
      "Telenor\n",
      "Aircel\n",
      "Sistema\n",
      "Quadrant\n",
      "Videocon\n",
      "Telewings\n",
      "Loop\n",
      "Unitech\n",
      "Aircel/Dishnet\n",
      "Quadrant (HFCL)\n",
      "S-Tel\n",
      "Etisalat\n",
      "Uninor\n",
      "HFCL\n",
      "Etisalat/Allianz\n",
      "Idea/Spice\n",
      "Vodafone Essar\n",
      "Loop Telecom Pvt. Ltd.\n",
      "HFCL Infotel\n",
      "Sistema Shyam Teleservices Ltd\n",
      "Spice\n",
      "BPL Mobile\n",
      "Tata Telecommunication\n",
      "STPL\n",
      "APSFL\n",
      "V-CON Mobile & Infra Pvt. Ltd.\n",
      "Bharti Airtel (including Tata Telecommunications)\n",
      "Reliance\n",
      "Tata\n",
      "Teleservice Ltd.\n",
      "Systema Shyam Teleservices Ltd.\n",
      "Number of unique service providers after cleaning:  42\n"
     ]
    }
   ],
   "source": [
    "a=df['service_provider'].unique()\n",
    "c=0\n",
    "for i in a:\n",
    "    print(i)\n",
    "    c+=1\n",
    "a #have to clean the data by inserting 0 in place empty values or ' ' values\n",
    "print('Number of unique service providers after cleaning: ',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bc8bf151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Andhra Pradesh', 'Assam', 'Bihar', 'Delhi', 'Gujarat', 'Haryana',\n",
       "       'Himachal Pradesh', 'Jammu and Kashmir', 'Karnataka', 'Kerala',\n",
       "       'Kolkata', 'Madhya Pradesh', 'Maharashtra', 'Mumbai', 'North East',\n",
       "       'Odisha', 'Punjab', 'Rajasthan', 'Tamil Nadu',\n",
       "       'Uttar Pradesh (East)', 'Uttar Pradesh (West)', 'West Bengal',\n",
       "       'All India', 'All india', 'Tamil Nadu (including Chennai)',\n",
       "       'Chennai', 'Andaman and Nicobar Islands', 'Arunachal Pradesh',\n",
       "       'Chhattisgarh', 'Jharkhand', 'Uttarakhand', 'North East 1',\n",
       "       'North East 2', 'North East2', 'North East1', 'Chattisgarh',\n",
       "       'Andaman and Nicobar', 'Uttaranchal'], dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=df['circle'].unique()\n",
    "a # have to remove the dupliacates and nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ce17c261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andhra Pradesh <class 'str'>\n",
      "Assam <class 'str'>\n",
      "Bihar <class 'str'>\n",
      "Delhi <class 'str'>\n",
      "Gujarat <class 'str'>\n",
      "Haryana <class 'str'>\n",
      "Himachal Pradesh <class 'str'>\n",
      "Jammu and Kashmir <class 'str'>\n",
      "Karnataka <class 'str'>\n",
      "Kerala <class 'str'>\n",
      "Kolkata <class 'str'>\n",
      "Madhya Pradesh <class 'str'>\n",
      "Maharashtra <class 'str'>\n",
      "Mumbai <class 'str'>\n",
      "North East <class 'str'>\n",
      "Odisha <class 'str'>\n",
      "Punjab <class 'str'>\n",
      "Rajasthan <class 'str'>\n",
      "Tamil Nadu <class 'str'>\n",
      "Uttar Pradesh (East) <class 'str'>\n",
      "Uttar Pradesh (West) <class 'str'>\n",
      "West Bengal <class 'str'>\n",
      "All India <class 'str'>\n",
      "All india <class 'str'>\n",
      "Tamil Nadu (including Chennai) <class 'str'>\n",
      "Chennai <class 'str'>\n",
      "Andaman and Nicobar Islands <class 'str'>\n",
      "Arunachal Pradesh <class 'str'>\n",
      "Chhattisgarh <class 'str'>\n",
      "Jharkhand <class 'str'>\n",
      "Uttarakhand <class 'str'>\n",
      "North East 1 <class 'str'>\n",
      "North East 2 <class 'str'>\n",
      "North East2 <class 'str'>\n",
      "North East1 <class 'str'>\n",
      "Chattisgarh <class 'str'>\n",
      "Andaman and Nicobar <class 'str'>\n",
      "Uttaranchal <class 'str'>\n",
      "Number of unique circle after cleaning: 38\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for i in a:\n",
    "    print(i,type(i))\n",
    "    c+=1\n",
    "print('Number of unique circle after cleaning:',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "812a069e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 <class 'numpy.int64'>\n",
      "2024 <class 'numpy.int64'>\n",
      "2023 <class 'numpy.int64'>\n",
      "2022 <class 'numpy.int64'>\n",
      "2021 <class 'numpy.int64'>\n",
      "2020 <class 'numpy.int64'>\n",
      "2019 <class 'numpy.int64'>\n",
      "2018 <class 'numpy.int64'>\n",
      "2017 <class 'numpy.int64'>\n",
      "2016 <class 'numpy.int64'>\n",
      "2015 <class 'numpy.int64'>\n",
      "2014 <class 'numpy.int64'>\n",
      "2013 <class 'numpy.int64'>\n",
      "2012 <class 'numpy.int64'>\n",
      "2011 <class 'numpy.int64'>\n",
      "2010 <class 'numpy.int64'>\n",
      "2009 <class 'numpy.int64'>\n",
      "Number of unique years after cleaning: 17\n"
     ]
    }
   ],
   "source": [
    "a=df['year'].unique()\n",
    "c=0\n",
    "for i in a:\n",
    "    print(i,type(i))\n",
    "    c+=1\n",
    "print('Number of unique years after cleaning:',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ed0b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8cb27179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        33965795\n",
       "1        12314102\n",
       "2        40967773\n",
       "3        18877637\n",
       "4        12401101\n",
       "           ...   \n",
       "70723           0\n",
       "70724           0\n",
       "70725           0\n",
       "70726           0\n",
       "70727           0\n",
       "Name: value, Length: 70728, dtype: int32"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Replace explicit empty strings (\"\") AND single-space strings (' ') with 0\n",
    "df['value'] = df['value'].replace(['', ' '], 0, regex=False)\n",
    "\n",
    "# 2. Convert the 'value' column to numeric. 'coerce' converts any remaining messy/non-numeric strings to NaN.\n",
    "df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "\n",
    "# 3. Fill any NaN values (either original missing or from step 2) with 0\n",
    "df['value'] = df['value'].fillna(0)\n",
    "\n",
    "# 4. Finally, ensure the entire column is an integer type (if appropriate for your data)\n",
    "df['value'] = df['value'].astype(int)\n",
    "df['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4cbb6e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22654\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for i in df['value']:\n",
    "    if i==0:\n",
    "        c+=1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4d11a22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 70728\n",
      "CSV files created:\n",
      "telecom_market_data_part1_10percent.csv → 7073 rows\n",
      "telecom_market_data_part2_10percent.csv → 7073 rows\n",
      "telecom_market_data_part3_80percent.csv → 56582 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "\n",
    "# Total rows\n",
    "total_rows = len(df)\n",
    "print(\"Total rows:\", total_rows)\n",
    "\n",
    "# Calculate split sizes\n",
    "first_split = round(total_rows * 0.10)   # 10%\n",
    "second_split = round(total_rows * 0.10)  # another 10%\n",
    "\n",
    "# Perform splits\n",
    "df1 = df.iloc[:first_split]                          # first 10%\n",
    "df2 = df.iloc[first_split:first_split+second_split]  # next 10%\n",
    "df3 = df.iloc[first_split+second_split:]             # remaining 80%\n",
    "\n",
    "# Save outputs\n",
    "df1.to_csv(\"telecom_market_data_part1_10percent.csv\", index=False)\n",
    "df2.to_csv(\"telecom_market_data_part2_10percent.csv\", index=False)\n",
    "df3.to_csv(\"telecom_market_data_part3_80percent.csv\", index=False)\n",
    "\n",
    "print(\"CSV files created:\")\n",
    "print(\"telecom_market_data_part1_10percent.csv →\", len(df1), \"rows\")\n",
    "print(\"telecom_market_data_part2_10percent.csv →\", len(df2), \"rows\")\n",
    "print(\"telecom_market_data_part3_80percent.csv →\", len(df3), \"rows\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
